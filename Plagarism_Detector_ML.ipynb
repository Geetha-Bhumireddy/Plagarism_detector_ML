{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd1d996c-4e6b-4f25-aa49-ba222c611dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\bhumi\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (8.1.7)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.9.11-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.66.6-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\bhumi\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 15.3 MB/s eta 0:00:00\n",
      "Downloading regex-2024.9.11-cp313-cp313-win_amd64.whl (273 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, joblib, nltk\n",
      "Successfully installed joblib-1.4.2 nltk-3.9.1 regex-2024.9.11 tqdm-4.66.6\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24701f92-8f42-4ced-acab-d703f2913112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\bhumi\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (2.1.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\bhumi\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.6/11.0 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.0/11.0 MB 14.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.9/11.0 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 14.0 MB/s eta 0:00:00\n",
      "Downloading scipy-1.14.1-cp313-cp313-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 4.7/44.5 MB 22.5 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 9.2/44.5 MB 21.6 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 14.2/44.5 MB 21.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 19.1/44.5 MB 22.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 23.9/44.5 MB 22.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 30.1/44.5 MB 23.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 35.7/44.5 MB 23.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.9/44.5 MB 23.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.5 MB 24.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 22.0 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, scikit-learn\n",
      "Successfully installed scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e3936d8-47f2-4ad8-8f4d-be2418cbbaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'popular'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\bhumi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection popular\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('popular')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ce082e4-ae1e-463a-ba45-c71b1a324c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9e3c3f-892b-4a36-9c46-eda86967c570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source_text</th>\n",
       "      <th>plagiarized_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Researchers have discovered a new species of b...</td>\n",
       "      <td>Scientists have found a previously unknown but...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The moon orbits the Earth in approximately 27....</td>\n",
       "      <td>Our natural satellite takes around 27.3 days t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Water is composed of two hydrogen atoms and on...</td>\n",
       "      <td>H2O consists of 2 hydrogen atoms and 1 oxygen ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The history of Rome dates back to 753 BC.</td>\n",
       "      <td>Rome has a long history that can be traced bac...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Pluto was once considered the ninth planet in ...</td>\n",
       "      <td>In the past, Pluto was classified as the ninth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        source_text  \\\n",
       "0           0  Researchers have discovered a new species of b...   \n",
       "1           1  The moon orbits the Earth in approximately 27....   \n",
       "2           2  Water is composed of two hydrogen atoms and on...   \n",
       "3           3          The history of Rome dates back to 753 BC.   \n",
       "4           4  Pluto was once considered the ninth planet in ...   \n",
       "\n",
       "                                    plagiarized_text  label  \n",
       "0  Scientists have found a previously unknown but...      1  \n",
       "1  Our natural satellite takes around 27.3 days t...      1  \n",
       "2  H2O consists of 2 hydrogen atoms and 1 oxygen ...      1  \n",
       "3  Rome has a long history that can be traced bac...      1  \n",
       "4  In the past, Pluto was classified as the ninth...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:/Users/bhumi/Downloads/Plagiarism-detector-using-machine-learning-main (1)/Plagiarism-detector-using-machine-learning-main/dataset.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64bd0acc-55c9-4532-9d9f-799223c927be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    187\n",
       "1    183\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae0c6a01-ed5f-4a08-9e5b-69c5af4ae7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text use dummy text'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "def preprocess_text(text):\n",
    "    text = text.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "    text = text.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = \" \".join((word for word in text.split() if word not in stop_words))\n",
    "    return text \n",
    "\n",
    "preprocess_text(\"This is my !#@#$#$%/ text to use for dummy text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c8df883-833b-400b-bee7-db147e318213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>source_text</th>\n",
       "      <th>plagiarized_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>researchers discovered new species butterfly a...</td>\n",
       "      <td>scientists found previously unknown butterfly ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>moon orbits earth approximately 273 days</td>\n",
       "      <td>natural satellite takes around 273 days comple...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>water composed two hydrogen atoms one oxygen atom</td>\n",
       "      <td>h2o consists 2 hydrogen atoms 1 oxygen atom</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>history rome dates back 753 bc</td>\n",
       "      <td>rome long history traced back 753 bc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>pluto considered ninth planet solar system</td>\n",
       "      <td>past pluto classified ninth planet suns planet...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>397</td>\n",
       "      <td>playing musical instruments enhances creativity</td>\n",
       "      <td>creativity enhanced playing musical instruments</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>398</td>\n",
       "      <td>studying history helps understanding present</td>\n",
       "      <td>understanding present aided studying history</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>399</td>\n",
       "      <td>listening classical music improve focus</td>\n",
       "      <td>focus improved listening classical music</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>400</td>\n",
       "      <td>practicing yoga enhances physical flexibility</td>\n",
       "      <td>physical flexibility enhanced practicing yoga</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>401</td>\n",
       "      <td>volunteering fosters community spirit</td>\n",
       "      <td>community spirit fostered volunteering</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>370 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                        source_text  \\\n",
       "0             0  researchers discovered new species butterfly a...   \n",
       "1             1           moon orbits earth approximately 273 days   \n",
       "2             2  water composed two hydrogen atoms one oxygen atom   \n",
       "3             3                     history rome dates back 753 bc   \n",
       "4             4         pluto considered ninth planet solar system   \n",
       "..          ...                                                ...   \n",
       "365         397    playing musical instruments enhances creativity   \n",
       "366         398       studying history helps understanding present   \n",
       "367         399            listening classical music improve focus   \n",
       "368         400      practicing yoga enhances physical flexibility   \n",
       "369         401              volunteering fosters community spirit   \n",
       "\n",
       "                                      plagiarized_text  label  \n",
       "0    scientists found previously unknown butterfly ...      1  \n",
       "1    natural satellite takes around 273 days comple...      1  \n",
       "2          h2o consists 2 hydrogen atoms 1 oxygen atom      1  \n",
       "3                 rome long history traced back 753 bc      1  \n",
       "4    past pluto classified ninth planet suns planet...      1  \n",
       "..                                                 ...    ...  \n",
       "365    creativity enhanced playing musical instruments      0  \n",
       "366       understanding present aided studying history      0  \n",
       "367           focus improved listening classical music      0  \n",
       "368      physical flexibility enhanced practicing yoga      0  \n",
       "369             community spirit fostered volunteering      0  \n",
       "\n",
       "[370 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['source_text'] = data['source_text'].apply(preprocess_text)\n",
    "data['plagiarized_text'] = data['plagiarized_text'].apply(preprocess_text)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79da75e7-6e4b-486c-81b6-7f7e2068dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(data['source_text']+\" \"+data['plagiarized_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01e817bd-29a3-4709-92d3-0fad34f5856d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c67a670-01e3-4e4b-b3be-13df93d1cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76250eb3-7eef-455e-991b-5fd1146d72b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8243243243243243\n",
      "Classification report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82        35\n",
      "           1       0.86      0.79      0.83        39\n",
      "\n",
      "    accuracy                           0.82        74\n",
      "   macro avg       0.83      0.83      0.82        74\n",
      "weighted avg       0.83      0.82      0.82        74\n",
      "\n",
      "Confusion Matrix :  [[30  5]\n",
      " [ 8 31]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(y_test,y_pred))\n",
    "print(\"Classification report : \", classification_report(y_test,y_pred))\n",
    "print(\"Confusion Matrix : \", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8714310b-9340-4935-99dd-b00da079eef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7972972972972973\n",
      "Classification report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.97      0.82        35\n",
      "           1       0.96      0.64      0.77        39\n",
      "\n",
      "    accuracy                           0.80        74\n",
      "   macro avg       0.83      0.81      0.79        74\n",
      "weighted avg       0.84      0.80      0.79        74\n",
      "\n",
      "Confusion Matrix :  [[34  1]\n",
      " [14 25]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(y_test,y_pred))\n",
    "print(\"Classification report : \", classification_report(y_test,y_pred))\n",
    "print(\"Confusion Matrix : \", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09301d4b-76dc-4f95-ba48-e473d09348f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8648648648648649\n",
      "Classification report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86        35\n",
      "           1       0.87      0.87      0.87        39\n",
      "\n",
      "    accuracy                           0.86        74\n",
      "   macro avg       0.86      0.86      0.86        74\n",
      "weighted avg       0.86      0.86      0.86        74\n",
      "\n",
      "Confusion Matrix :  [[30  5]\n",
      " [ 5 34]]\n"
     ]
    }
   ],
   "source": [
    " from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(y_test,y_pred))\n",
    "print(\"Classification report : \", classification_report(y_test,y_pred))\n",
    "print(\"Confusion Matrix : \", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b616674d-b719-4f1d-83e0-d835d569bbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8783783783783784\n",
      "Classification report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87        35\n",
      "           1       0.89      0.87      0.88        39\n",
      "\n",
      "    accuracy                           0.88        74\n",
      "   macro avg       0.88      0.88      0.88        74\n",
      "weighted avg       0.88      0.88      0.88        74\n",
      "\n",
      "Confusion Matrix :  [[31  4]\n",
      " [ 5 34]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(kernel='linear', random_state=42)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy : \", accuracy_score(y_test,y_pred))\n",
    "print(\"Classification report : \", classification_report(y_test,y_pred))\n",
    "print(\"Confusion Matrix : \", confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "553cb00a-1fd0-4638-aed8-4d8fe2ce5337",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model,open('model.pkl','wb'))\n",
    "pickle.dump(tfidf_vectorizer, open('tfidf_vectorizer.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cee7e0d-fef3-4de5-a228-cd7ac37c7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('model.pkl','rb'))\n",
    "tfidf_vectorizer = pickle.load(open('tfidf_vectorizer.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8eb46c2-b646-4506-8e98-b182e1490fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(input_text):\n",
    "    vectorized_text = tfidf_vectorizer.transform([input_text])\n",
    "    result = model.predict(vectorized_text)\n",
    "    return \"Plagaiarism Detected\" if result[0]==1 else \"No Plagiarism\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "012f0cb4-75e5-4c38-bc97-7b21f6052fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Plagaiarism Detected'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"Researchers have discovered a new species of butterfly in the Amazon rainforest.\"\n",
    "detect(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "249b74b7-8fa2-4340-b277-9f5b6b7e9716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No Plagiarism'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"Researchers have discovered\"\n",
    "detect(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b077765-2db7-456e-83b9-f0f6829d8554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.2'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0817bb-3ceb-4aa7-812f-f322d0db4a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4925077-1de7-40a0-8509-24542890da3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
